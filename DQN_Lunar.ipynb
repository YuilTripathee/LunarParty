{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ff62ab-d5b2-43c4-9447-32970bbb472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.3.0 in ./venv/lib/python3.10/site-packages (from gymnasium) (4.13.2)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: farama-notifications, numpy, cloudpickle, gymnasium\n",
      "Successfully installed cloudpickle-3.1.1 farama-notifications-0.0.4 gymnasium-1.1.1 numpy-2.2.6\n",
      "Requirement already satisfied: gymnasium[accept-rom-license,atari] in ./venv/lib/python3.10/site-packages (1.1.1)\n",
      "\u001b[33mWARNING: gymnasium 1.1.1 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: farama-notifications>=0.0.1 in ./venv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./venv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./venv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv/lib/python3.10/site-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
      "Collecting ale_py>=0.9\n",
      "  Downloading ale_py-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ale_py\n",
      "Successfully installed ale_py-0.11.0\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: gymnasium[box2d] in ./venv/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./venv/lib/python3.10/site-packages (from gymnasium[box2d]) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./venv/lib/python3.10/site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./venv/lib/python3.10/site-packages (from gymnasium[box2d]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv/lib/python3.10/site-packages (from gymnasium[box2d]) (3.1.1)\n",
      "Collecting pygame>=2.1.3\n",
      "  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting box2d-py==2.3.5\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting swig==4.*\n",
      "  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing legacy 'setup.py install' for box2d-py, since package 'wheel' is not installed.\n",
      "Installing collected packages: swig, box2d-py, pygame\n",
      "  Running setup.py install for box2d-py ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed box2d-py-2.3.5 pygame-2.6.1 swig-4.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
    "!apt-get install -y swig\n",
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa553cae-3082-4f91-a333-8313c265d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from collections import deque, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3dd712-4240-47d5-8579-a612c42fa923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 25 14:24:49 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0  On |                  N/A |\n",
      "| 36%   42C    P5              42W / 370W |    564MiB / 24576MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1492      G   /usr/lib/xorg/Xorg                          236MiB |\n",
      "|    0   N/A  N/A      2160      G   /usr/bin/gnome-shell                         56MiB |\n",
      "|    0   N/A  N/A      2956      G   ...erProcess --variations-seed-version       66MiB |\n",
      "|    0   N/A  N/A      5370      G   /opt/brave.com/brave/brave                    4MiB |\n",
      "|    0   N/A  N/A      5413      G   ...44,262144 --variations-seed-version       58MiB |\n",
      "|    0   N/A  N/A     69150      G   ...irefox/6198/usr/lib/firefox/firefox      120MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4483d4c1-9200-4ced-884d-52d550faf2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3703d90c-796c-4def-bdb8-0057908c5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "  def __init__(self, state_size, action_size, seed=42):\n",
    "    super(Network, self).__init__()\n",
    "    self.seed=torch.manual_seed(seed)\n",
    "    self.fc1=nn.Linear(state_size,64)\n",
    "    self.fc2=nn.Linear(64,64)\n",
    "    self.fc3=nn.Linear(64,action_size)\n",
    "\n",
    "  def forward(self,state):\n",
    "    x=self.fc1(state)\n",
    "    x=F.relu(x)\n",
    "    x=self.fc2(x)\n",
    "    x=F.relu(x)\n",
    "    return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116dda66-282d-4ea2-99bc-f9091cdf26ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape : (8,)\n",
      "State Size : 8\n",
      "Number of Actions : 4\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env=gym.make(\"LunarLander-v3\")\n",
    "state_shape=env.observation_space.shape\n",
    "state_size=env.observation_space.shape[0]\n",
    "number_action=env.action_space.n\n",
    "print('State Shape :',state_shape)\n",
    "print('State Size :',state_size)\n",
    "print('Number of Actions :',number_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3222d590-f76e-4c2c-8539-aa5ba01f37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "env = RecordVideo(env, video_folder='videos/', episode_trigger=lambda x: x % 100 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3d745b-08ba-494e-aaef-db2352bddc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v3', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33349033-9a47-4014-8a85-5dca886b0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(agent, env, filename=\"videos/episode.mp4\", epsilon=0.0):\n",
    "    frames = []\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        frames.append(env.render())\n",
    "        action = agent.act(state, epsilon)\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "    imageio.mimsave(filename, frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9bb5fc-3472-4c7b-95e6-3e7e1b3e6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-4\n",
    "minibatch_size=100\n",
    "discount_factor=0.99\n",
    "replay_buffer_size=int(1e5)\n",
    "interpolation_parameter=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83d216c-4e71-42dd-b5dc-5e0fa390aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory(object):\n",
    "  def __init__(self,capacity):\n",
    "    self.device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.capacity=capacity\n",
    "    self.memory=[]\n",
    "\n",
    "  def push(self,event):\n",
    "    self.memory.append(event)\n",
    "    if len(self.memory)>self.capacity:\n",
    "      del self.memory[0]\n",
    "\n",
    "  def sample(self,batch_size):\n",
    "    experiences=random.sample(self.memory,k=batch_size)\n",
    "    states=torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device)\n",
    "    actions=torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long().to(self.device)\n",
    "    rewards=torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device)\n",
    "    next_states=torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device)\n",
    "    dones=torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
    "    return states,next_states,actions,rewards,dones\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a47c03-b959-4743-abff-e1b57fe1dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "  #local_qnetwork--> selects the action\n",
    "  #target_qnetwork --> calculate target queue values in the local network\n",
    "  #double queue network stablizes the learning process\n",
    "  def __init__(self,state_size,action_size):\n",
    "    self.device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.state_size=state_size\n",
    "    self.action_size=action_size\n",
    "    self.local_qnetwork=Network(state_size,action_size).to(self.device)\n",
    "    self.target_qnetwork=Network(state_size,action_size).to(self.device)\n",
    "    self.optimizer=optim.Adam(self.local_qnetwork.parameters(),lr=learning_rate)\n",
    "    self.memory=ReplayMemory(replay_buffer_size)\n",
    "    self.t_step=0\n",
    "\n",
    "  def step(self,state,action,reward,next_state,done):\n",
    "    self.memory.push((state,action,reward,next_state,done))\n",
    "    self.t_step=(self.t_step + 1) % 4\n",
    "    if self.t_step==0:\n",
    "      if len(self.memory.memory)>minibatch_size:\n",
    "        experiences=self.memory.sample(100)\n",
    "        self.learn(experiences,discount_factor)\n",
    "\n",
    "  #act() --> choose action based on action policy\n",
    "  def act(self,state,epsilon=0.):\n",
    "    state=torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "    self.local_qnetwork.eval()\n",
    "    with torch.no_grad():\n",
    "      action_values=self.local_qnetwork(state)\n",
    "    self.local_qnetwork.train()\n",
    "    if random.random()>epsilon:\n",
    "      return np.argmax(action_values.cpu().data.numpy())\n",
    "    else:\n",
    "      return random.choice(np.arange(self.action_size))\n",
    "\n",
    "  #leann() --> agent learns from the replay memory\n",
    "  def learn(self,experiences,discount_factor):\n",
    "    states,next_states,actions,rewards,dones=experiences\n",
    "    next_q_targets=self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    q_targets=rewards + (discount_factor*next_q_targets*(1-dones))\n",
    "    q_expected=self.local_qnetwork(states).gather(1,actions)\n",
    "    loss=F.mse_loss(q_expected,q_targets)\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "    self.soft_update(self.local_qnetwork,self.target_qnetwork,interpolation_parameter)\n",
    "\n",
    "  #soft_update() --> update target_qnetwork parameters by blending them with local_qnetwork (prevent abrupt changes which could destablize the training)\n",
    "  def soft_update(self,local_model,target_model,interpolation_parameter):\n",
    "    for target_param,local_param in zip(target_model.parameters(),local_model.parameters()):\n",
    "      target_param.data.copy_(interpolation_parameter*local_param.data+(1.0-interpolation_parameter)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894ddd8d-0bd1-4d82-911b-1a5fa3e47262",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size,number_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43baca6e-38c2-487a-95b6-4e982abb0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -93.43"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -93.43\n",
      "Episode 200\tAverage Score: -22.39"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200\tAverage Score: -22.39\n",
      "Episode 300\tAverage Score: 93.940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300\tAverage Score: 93.94\n",
      "Episode 380\tAverage Score: 200.63\n",
      "Environment solved in 280 episodes!\tAverage Score: 200.63\n"
     ]
    }
   ],
   "source": [
    "number_episodes=2000\n",
    "maximum_number_timesteps_per_episode=1000\n",
    "epsilon_starting_value=1.0\n",
    "epsilon_ending_value=0.01\n",
    "epsilon_decay_value=0.995\n",
    "epsilon=epsilon_starting_value\n",
    "scores_on_100_episodes=deque(maxlen=100)\n",
    "\n",
    "for episode in range(1,number_episodes+1):\n",
    "  state,_=env.reset()\n",
    "  score=0\n",
    "  for t in range(maximum_number_timesteps_per_episode):\n",
    "    action=agent.act(state,epsilon)\n",
    "    next_state,reward,done,_,_=env.step(action)\n",
    "    agent.step(state,action,reward,next_state,done)\n",
    "    state=next_state\n",
    "    score+=reward\n",
    "    if done:\n",
    "      break;\n",
    "  scores_on_100_episodes.append(score)\n",
    "  epsilon=max(epsilon_ending_value,epsilon_decay_value*epsilon)\n",
    "  print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode,np.mean(scores_on_100_episodes)),end=\"\")\n",
    "  if episode%100==0:\n",
    "    record_video(agent, env, f\"videos/episode_{episode}.mp4\")\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode,np.mean(scores_on_100_episodes)))\n",
    "  if np.mean(scores_on_100_episodes)>=200.0:\n",
    "    print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(episode-100,np.mean(scores_on_100_episodes)))\n",
    "    torch.save(agent.local_qnetwork.state_dict(),'checkpoint.pth')\n",
    "    break;\n",
    "  # if episode % 50 == 0:\n",
    "  #   record_video(agent, env, f\"videos/episode_{episode}.mp4\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144e498a-8ce4-4038-bf0e-fd2ef6151d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_video_of_model(agent, env_name):\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frame = env.render()\n",
    "        frames.append(frame)\n",
    "        action = agent.act(state)\n",
    "        state, reward, done, _, _ = env.step(action.item())\n",
    "    env.close()\n",
    "    imageio.mimsave('video.mp4', frames, fps=30)\n",
    "\n",
    "show_video_of_model(agent, 'LunarLander-v3')\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(data=''''''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fa93b-f345-4c5d-bbeb-f63cd090ad7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
